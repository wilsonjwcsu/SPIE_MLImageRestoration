{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e2a99a-f4a9-404f-8d54-187f2c8f599f",
   "metadata": {},
   "source": [
    "# Classification demo\n",
    "SPIE Short course on Machine Learning for Image Restoration.  \n",
    "Author: Jesse Wilson (jesse.wilson@colostate.edu).\n",
    "\n",
    "Walk through training and evaluation of a convolutional network for handwritten digits classification. This code is provided for educational purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d211e62-a7ba-4a52-8c70-47a70ad8946b",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405766f-e4ce-4620-831a-e1ba600dd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and set up GPU device for training\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\" # bug workaround needed on my laptop--not sure why\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "# get available GPU \n",
    "# supports NVIDIA (CUDA), Intel (XPU), and Apple (MPS)\n",
    "# (CAUTION: AI-generated code -- NOT validated on all systems!)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif hasattr(torch,\"xpu\") and torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu:0\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Selected device: {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22b329-0709-42d1-a30d-d0fe73b737f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "# on my laptop (anaconda / windows / Intel XPU), the KMP_DUPLICATE_LIB_OK workaround needed to avoid crashing the kernel\n",
    "batch_size=32\n",
    "\n",
    "# load datasets, and automatically transform images to pytorch tensor format\n",
    "transform = transforms.ToTensor()\n",
    "dataset_train = datasets.MNIST(root='data',train=True,download=True,transform=transform)\n",
    "dataset_val = datasets.MNIST(root='data',train=False,download=True,transform=transform)\n",
    "\n",
    "# Set up dataloaders, which produce batches of data for training and validation\n",
    "dataloader_train = DataLoader(dataset_train, batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size, shuffle=False)\n",
    "\n",
    "# sanity check -- plot the first image from the training dataloader\n",
    "img = next(iter(dataloader_train))[0][1].squeeze()\n",
    "plt.imshow(img)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fdce27-72ea-4a0e-a8a7-7dacf1dc7dc6",
   "metadata": {},
   "source": [
    "# Neural network definition and quick passthrough test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf05a54-ad7e-46a4-8b43-290c1faba6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN classifier neural network \n",
    "# Based roughly on Stevens, Antiga & Viehmann Deep Learning with Pytorch CH 8 example\n",
    "#\n",
    "# This sets up a new class, inheriting from the pytorch nn.Module class.\n",
    "# At bare minimum we need to implement __init__() and forward() functions\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # this initializes the parent nn.Module\n",
    "\n",
    "        # define network elements\n",
    "        \n",
    "        # convolutional front end (feature extraction)\n",
    "        self.conv1 = nn.Conv2d(1,16,kernel_size=3,padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1=nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16,16,kernel_size=3,padding=1)\n",
    "        self.act2=nn.ReLU()\n",
    "        self.pool2=nn.MaxPool2d(2)\n",
    "\n",
    "        # fully connected back end (classifier)\n",
    "        self.fc1=nn.Linear(7*7*16,32)\n",
    "        self.act3=nn.ReLU()\n",
    "        self.fc2=nn.Linear(32,10)\n",
    "\n",
    "        # initialize learnable parameters\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                nn.init.constant_(m.bias,0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # first, pass through convolutional front end and extract features\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "\n",
    "        # flatten to a vector and pass through the fully connected classifier\n",
    "        out = out.view(-1,7*7*16)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def forwardWithProbabilities(self, x):\n",
    "        out = self.forward(x)\n",
    "        out = F.softmax(out,dim=1)\n",
    "        return out\n",
    "\n",
    "# instantiate our new class and assign it to the hardware device\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d533b4-bcfe-4de7-a277-2154709dbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a saved model\n",
    "# DO NOT RUN THIS THE FIRST TIME AROUND\n",
    "net.load_state_dict(torch.load(\"classification_demo.pth\", weights_only=True))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f227f0c-b6d7-420c-b3eb-83df5ab67b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check running data through the network\n",
    "data = next(iter(dataloader_val))\n",
    "x = data[0].to(device) # image\n",
    "y = data[1] # label (target)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = net(x) # estimated label\n",
    "\n",
    "# yhat is a vector of probabilities for each class\n",
    "probs = F.softmax(yhat,dim=1)\n",
    "print(probs[0])\n",
    "\n",
    "# the predicted class is the one with the maximum probability\n",
    "predicted = yhat.argmax(dim=1)\n",
    "\n",
    "# show a random selection of images and labels\n",
    "for plotInd in range(9):\n",
    "    ind = randint(0,len(x)-1)\n",
    "    \n",
    "    plt.subplot(3,3,plotInd+1)\n",
    "    plt.imshow(x[ind].cpu().squeeze())\n",
    "    plt.title(f'predicted: {predicted[ind]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336bab75-1503-46dd-8318-65d641acf29e",
   "metadata": {},
   "source": [
    "# Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65be2b-81f2-4266-bbb5-de679a5b4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "#loss_fn = nn.BCELoss() # binary cross-entropy loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_train_vec = [] # history of training dataset loss\n",
    "loss_val_vec = [] # history of validation set loss\n",
    "accuracy_val_vec = [] # history of validation set accuracy\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    net.train() # put network in training mode\n",
    "    loss_this_epoch = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    # iterate through the training dataset\n",
    "    for data, label in dataloader_train:\n",
    "        # prep data\n",
    "        x = data.to(device)\n",
    "        #y = F.one_hot(label,10).to(torch.float).to(device) # convert label to one-hot coding\n",
    "        y = label.to(device)\n",
    "\n",
    "        # pass through network and evaluate loss function\n",
    "        yhat = net(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "\n",
    "        # gradient descent step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of loss function values over time\n",
    "        loss_this_epoch += loss.sum()\n",
    "        n_samples += len(x)\n",
    "\n",
    "    loss_this_epoch = loss_this_epoch / n_samples\n",
    "    loss_train_vec += [loss_this_epoch.item()]\n",
    "\n",
    "    \n",
    "    net.eval() # put network in evalution mode\n",
    "    loss_this_epoch = 0\n",
    "    correct_this_epoch = 0\n",
    "    n_samples = 0\n",
    "    # iterate through validation set\n",
    "    for data, label in dataloader_val:\n",
    "        with torch.no_grad(): # DON'T CALCULATE GRADIENTS!\n",
    "            x = data.to(device)\n",
    "            y = F.one_hot(label,10).to(torch.float).to(device) # convert label to one-hot coding\n",
    "\n",
    "            # pass through network and evaluate loss function\n",
    "            yhat = net(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "    \n",
    "            loss_this_epoch += loss.sum()\n",
    "\n",
    "            # calculate accuracy\n",
    "            predicted = yhat.argmax(dim=1).cpu()\n",
    "            correct = (predicted == label).sum()\n",
    "            correct_this_epoch += correct\n",
    "\n",
    "            n_samples += len(x)\n",
    "    \n",
    "    loss_this_epoch = loss_this_epoch / n_samples\n",
    "    loss_val_vec += [loss_this_epoch.item()]\n",
    "\n",
    "    accuracy_this_epoch = correct_this_epoch / n_samples\n",
    "    accuracy_val_vec += [accuracy_this_epoch.item()]\n",
    "\n",
    "\n",
    "    # save the model if it achieved a minimum validation loss\n",
    "    if loss_val_vec[-1] == min(loss_val_vec):\n",
    "        torch.save(net.state_dict(), \"classification_demo.pth\")\n",
    "\n",
    "    # plot losses\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=[10,4])\n",
    "    plt.subplot(121)\n",
    "    plt.plot(loss_train_vec)\n",
    "    plt.plot(loss_val_vec)\n",
    "    plt.title('losses')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training','validation'])\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(accuracy_val_vec, color=\"#ff7f0e\")\n",
    "    plt.title('validation accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.grid()\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527822c-cdd9-4977-ac2a-2ea3e7edd344",
   "metadata": {},
   "source": [
    "# Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428503f-f1ad-4e7a-91fc-7012f9290424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your turn: change one thing above and run it again. A few ideas\n",
    "# - change batch size\n",
    "# - change learning rate\n",
    "# - change from Adam to SGD optimizer\n",
    "# - number of channels per convolutional filter\n",
    "# - number of layers in the network\n",
    "# - number of neurons in FC1\n",
    "# - change ReLU to LeakyReLU or Sigmoid activation function\n",
    "# - change binary cross entropy to L1 or MSE loss functions\n",
    "# - change model saving condition to retain the model with best validation accuracy, rather than lowest loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd501cd3-58d5-43bc-8458-4f9f91ff491e",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26297a-ed97-4719-9244-476d8f5ccfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try something out of distribution\n",
    "batch_size=32\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "dataset_ood = datasets.FashionMNIST(root='data',train=False,download=True,transform=transform)\n",
    "\n",
    "dataloader_ood = DataLoader(dataset_ood, batch_size, shuffle=True)\n",
    "\n",
    "img = next(iter(dataloader_ood))[0][1].squeeze()\n",
    "plt.imshow(img)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee3723-d2cc-486d-bf43-2860894678eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check running data through the network\n",
    "data = next(iter(dataloader_ood))\n",
    "x = data[0].to(device) # image\n",
    "y = data[1] # label (target)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = net(x) # estimated label\n",
    "    \n",
    "maxval, maxind = yhat.max(dim=1)\n",
    "predicted = maxind\n",
    "confidence = maxval\n",
    "\n",
    "# show a random selection of images and labels\n",
    "for plotInd in range(9):\n",
    "    ind = randint(0,len(x)-1)\n",
    "    \n",
    "    plt.subplot(3,3,plotInd+1)\n",
    "    plt.imshow(x[ind].cpu().squeeze())\n",
    "    plt.title(f'pred: {predicted[ind]} ({maxval[ind]*100 :.2f}%)')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
