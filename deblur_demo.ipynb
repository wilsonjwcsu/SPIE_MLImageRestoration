{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a1cb62-2f11-45be-a12d-6c7432c55d0a",
   "metadata": {},
   "source": [
    "# Deconvolution demo.\n",
    "SPIE Short course on Machine Learning for Image Restoration.  \n",
    "Author: Jesse Wilson (jesse.wilson@colostate.edu).\n",
    "\n",
    "Walk through training and evaluation of a convolutional network for denoising. This code is provided for educational purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933f86e-1948-41a0-a98c-25cb5c76bffa",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a07d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\" # bug workaround needed on my laptop--not sure why\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from torch import fft\n",
    "\n",
    "# get available GPU \n",
    "# supports NVIDIA (CUDA), Intel (XPU), and Apple (MPS)\n",
    "# (CAUTION: AI-generated code -- NOT validated on all systems!)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif hasattr(torch,\"xpu\") and torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu:0\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Selected device: {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be014ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Pad((18,18,18,18))])\n",
    "dataset_train = datasets.MNIST(root='data',train=True,download=True,transform=transform)\n",
    "dataset_val = datasets.MNIST(root='data',train=False,download=True,transform=transform)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size, shuffle=False)\n",
    "\n",
    "img = next(iter(dataloader_train))[0][1].squeeze()\n",
    "plt.imshow(img)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45cb91-ab0b-4467-97f3-605b8a5e77be",
   "metadata": {},
   "source": [
    "# Set up a class to simulate the optical system\n",
    "Assumes spatially-invariant PSF resulting from a 4f system. Incoherent imaging. For more information, see [Voelz _Computational Fourier Optics: A MATLAB Tutorial_](https://www.spiedigitallibrary.org/ebooks/TT/Computational-Fourier-Optics-A-MATLAB-Tutorial/eISBN-9780819482051/10.1117/3.858456)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ea0e7-1afc-4398-843e-c4467f5ab2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a (incoherent) PSF\n",
    "class ForwardModel( nn.Module ):\n",
    "    def __init__(self, pupil_width=0.5, ny=64, nx=64):\n",
    "        super().__init__()\n",
    "\n",
    "        # set up sampling grid\n",
    "        dx = 2 / nx\n",
    "        x = torch.linspace(-1,1-dx,nx)\n",
    "        y = x\n",
    "        X,Y = torch.meshgrid(x,y)\n",
    "        R=torch.sqrt(X**2+Y**2)\n",
    "        CTF = R < torch.Tensor([pupil_width])\n",
    "\n",
    "        # set up OTF\n",
    "        CSF = fft.fftshift(fft.ifft2(fft.ifftshift(CTF)))\n",
    "        PSF = CSF.abs()**2\n",
    "        OTF = fft.fftshift(fft.fft2(fft.ifftshift(PSF)))\n",
    "        OTF = OTF / torch.max(OTF.abs())\n",
    "        self.OTF = OTF\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolve image with PSF by product with OTF in Fourier domain\n",
    "        img_f = fft.fftshift(fft.fft2(fft.ifftshift(x)))\n",
    "        img2_f = img_f * self.OTF\n",
    "        img2 = fft.fftshift(fft.ifft2(fft.ifftshift(img2_f)))\n",
    "        img2 = img2.real\n",
    "        img2 = F.relu(img2)\n",
    "        return img2\n",
    "\n",
    "x = dataset_train[0][0]\n",
    "forwardModel = ForwardModel(0.2)\n",
    "y = forwardModel(x)\n",
    "plt.subplot(121)\n",
    "plt.imshow(x.squeeze())\n",
    "plt.axis(\"off\")\n",
    "plt.title('object')\n",
    "plt.subplot(122)\n",
    "plt.imshow(y.squeeze())\n",
    "plt.axis('off')\n",
    "plt.title('image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392081a3-7c90-402e-b69a-375e7be96206",
   "metadata": {},
   "source": [
    "# Neural network definition and quick passthrough test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5f058-705c-4b07-a9a9-c98bceb37ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple u-net\n",
    "# Here we use  average pooling and interpolation instead of strided convolutions,\n",
    "# as it is less prone to grid-like artifacts in the output\n",
    "class UNet( nn.Module ):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downconv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, padding=1) # 64x64\n",
    "        self.downconv2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding=1) # 32x32\n",
    "        self.downconv3 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding=1) # 16x16\n",
    "        self.downconv4 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding=1) # 8x8\n",
    "\n",
    "        self.upconv1 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding=1) # 4x4\n",
    "        self.upconv2 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3, padding=1) # 8x8\n",
    "        self.upconv3 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3, padding=1) # 16x16\n",
    "        self.upconv4 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3, padding=1) # 32x32\n",
    "\n",
    "        self.outconv = nn.Conv2d(in_channels = 64, out_channels = 1, kernel_size = 3, padding=1, bias=False) # 64x64\n",
    "\n",
    "        # initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.)     \n",
    "\n",
    "    def forward(self, x):\n",
    "        featdown1 = F.leaky_relu(self.downconv1(x)) # 64x64\n",
    "        featdown2 = F.leaky_relu(self.downconv2(F.avg_pool2d(featdown1,2))) # 32x32\n",
    "        featdown3 = F.leaky_relu(self.downconv3(F.avg_pool2d(featdown2,2))) # 16x16\n",
    "        featdown4 = F.leaky_relu(self.downconv4(F.avg_pool2d(featdown3,2))) # 8x8\n",
    "\n",
    "        featup1 = F.interpolate(F.leaky_relu(self.upconv1(F.avg_pool2d(featdown4,2))),scale_factor=2,mode='bilinear') # 8x8\n",
    "        skip1 = torch.cat((featdown4, featup1),1) # 8x8\n",
    "        featup2 = F.interpolate(F.leaky_relu(self.upconv2(skip1)), scale_factor=2,mode='bilinear') # 16x16\n",
    "        skip2 = torch.cat((featdown3, featup2),1) # 16x16\n",
    "        featup3 = F.interpolate(F.leaky_relu(self.upconv3(skip2)), scale_factor=2, mode='bilinear') # 32x32\n",
    "        skip3 = torch.cat((featdown2, featup3),1) # 32x32\n",
    "        featup4 = F.interpolate(F.leaky_relu(self.upconv4(skip3)), scale_factor=2, mode='bilinear') # 64x64\n",
    "        skip4 = torch.cat((featdown1, featup4),1) # 64x64\n",
    "        out = self.outconv(skip4) # 64x64\n",
    "\n",
    "        # clamp output range to 0->1\n",
    "        # this is needed for the unsupervised demo later on.\n",
    "        # without it, the gradient loss term produces nonsensical results\n",
    "        out = torch.clamp(out,min=0,max=1) \n",
    "        \n",
    "        return out\n",
    "\n",
    "net = UNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33b50e-280c-438d-bba5-149d84d2d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a batch of images through the network\n",
    "img = next(iter(dataloader_train))[0][1]\n",
    "\n",
    "xhat = net(img.to(device).unsqueeze(0))\n",
    "print(xhat.shape)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[0].cpu().squeeze())\n",
    "plt.colorbar()\n",
    "plt.title('network input')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(xhat[0].detach().cpu().squeeze())\n",
    "plt.colorbar()\n",
    "plt.title('network output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175475b2-2092-4918-8c62-b3d9c20eaaa1",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed8b2c-bf01-4d78-bd39-8ba562dea2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised training\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "loss_fn = nn.MSELoss()\n",
    "forwardModel.OTF = forwardModel.OTF.to(device)\n",
    "\n",
    "\n",
    "loss_train_vec = []\n",
    "\n",
    "# training loop\n",
    "n_epochs = 10\n",
    "i_iter = 0\n",
    "for epoch in range(1,n_epochs):\n",
    "    for data, label in dataloader_train:\n",
    "        x = data.to(device)\n",
    "        y = forwardModel(x)\n",
    "        xhat = net(x)\n",
    "    \n",
    "        # compare recovered image with ground truth\n",
    "        loss = loss_fn(xhat,x)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        loss_train_vec += [loss.item()]\n",
    "        i_iter += 1\n",
    "    \n",
    "        # plot training/validation loss curves\n",
    "        if i_iter % 20 == 0:\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=[8,8])\n",
    "            plt.subplot(241)\n",
    "            plt.imshow(x[0].cpu().squeeze())\n",
    "            plt.axis('off')\n",
    "            plt.title('object')\n",
    "            plt.subplot(242)\n",
    "            plt.imshow(y[0].cpu().squeeze())\n",
    "            plt.axis('off')\n",
    "            plt.title('image')\n",
    "            plt.subplot(243)\n",
    "            plt.imshow(xhat[0].detach().cpu().squeeze())\n",
    "            plt.axis(\"off\")\n",
    "            plt.title('net output')\n",
    "            plt.subplot(212)\n",
    "            plt.plot(loss_train_vec)\n",
    "            plt.title(f'epoch {epoch}, iter {i_iter}')\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b2097-fc3c-4f1d-8c72-78f2207854e6",
   "metadata": {},
   "source": [
    "# Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd9fcb-6cc3-4d3e-9fd2-581d0b84b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your turn: change one thing above and run it again. A few ideas\n",
    "# - change pupil diameter\n",
    "# - change learning rate\n",
    "# - try L1 loss instead of MSE loss\n",
    "# - change neural network architecture\n",
    "# - add validation tracking to the training loop\n",
    "# - test on out-of-distribution images\n",
    "# - add noise to simulated image\n",
    "# - compare with Wiener deconvolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2b7ea-792a-4abb-903d-e9b64d7d3cac",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7855aab2-017e-4960-9ec4-f8c2afcba7f4",
   "metadata": {},
   "source": [
    "## Physics-informed (unsupervised) learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c9c8b-4c41-4154-8377-37d7bde54ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientMagnitude(nn.Module):\n",
    "    def __init__(self,dev):\n",
    "        super().__init__()\n",
    "        self.sobel_x = torch.tensor([[1.,0.,-1.],[2.,0.,-2.],[1.,0.,1.]]).unsqueeze(0).unsqueeze(0).to(dev)\n",
    "        self.sobel_y = torch.tensor([[1.,2.,1.],[0.,0.,0.],[-1.,-2.,-1.]]).unsqueeze(0).unsqueeze(0).to(dev)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # calculate summed magnitude of the gradients of an image\n",
    "        grad_x = F.conv2d(x,self.sobel_x)\n",
    "        grad_y = F.conv2d(x,self.sobel_y)\n",
    "    \n",
    "        absgrad = torch.abs(grad_x)**2 + torch.abs(grad_y)**2\n",
    "        return torch.mean(absgrad)\n",
    "\n",
    "class LaplacianVariance(nn.Module):\n",
    "    # alternative loss function for sharpness\n",
    "    # rough draft only -- UNTESTED\n",
    "    def __init__(self,dev):\n",
    "        super().__init__()\n",
    "        self.kernel = torch.tensor([[0.25,0.5,0.25],[0.5,-3.,0.5],[0.25,0.5,0.25]]).unsqueeze(0).unsqueeze(0).to(dev)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # calculate summed magnitude of the gradients of an image\n",
    "        L = F.conv2d(x,self.kernel)\n",
    "        v = torch.var(L)\n",
    "        \n",
    "        return v        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsupervised training\n",
    "# sometimes gets stuck producing blank output, may need to restart a few times\n",
    "# to obtain reasonable results\n",
    "net = UNet().to(device)\n",
    "\n",
    "# results are extremely sensitive to lr and lambda_gradmag\n",
    "lr = 0.001\n",
    "lambda_gradmag = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',patience=10,cooldown=10)\n",
    "loss_fn = nn.L1Loss()\n",
    "loss_fn_gradmag = GradientMagnitude(device)\n",
    "forwardModel.OTF = forwardModel.OTF.to(device)\n",
    "\n",
    "loss_train_vec = []\n",
    "\n",
    "ind = 0\n",
    "x = dataset_train[ind][0].to(device)\n",
    "y = forwardModel(x)\n",
    "\n",
    "# training loop\n",
    "n_epochs = 1000\n",
    "for epoch in range(1,n_epochs):\n",
    "    xhat = net(y.unsqueeze(0))\n",
    "\n",
    "    # pass output through imaging system\n",
    "    yhat = forwardModel(xhat)\n",
    "    \n",
    "\n",
    "    # compare recovered image with measurement\n",
    "    loss = loss_fn(yhat,y) - lambda_gradmag*loss_fn_gradmag(xhat)\n",
    "    #loss = loss_fn(yhat,y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step(loss)\n",
    "\n",
    "    loss_train_vec += [loss.item()]\n",
    "    \n",
    "    # plot training/validation loss curves\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=[8,8])\n",
    "    plt.subplot(241)\n",
    "    plt.imshow(x.cpu().squeeze())\n",
    "    plt.subplot(242)\n",
    "    plt.imshow(y.cpu().squeeze())\n",
    "    plt.subplot(243)\n",
    "    plt.imshow(xhat.detach().cpu().squeeze())\n",
    "    plt.subplot(244)\n",
    "    plt.imshow(yhat.detach().cpu().squeeze())\n",
    "    plt.subplot(212)\n",
    "    plt.plot(loss_train_vec)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce86619",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = randint(0,(len(dataset_train)-1))\n",
    "\n",
    "x = dataset_train[ind][0].to(device)\n",
    "y = forwardModel(x)\n",
    "with torch.no_grad():\n",
    "    xhat = net(y.unsqueeze(0))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(y.cpu().squeeze())\n",
    "plt.title('blurry')\n",
    "plt.subplot(132)\n",
    "plt.imshow(xhat.cpu().squeeze())\n",
    "plt.title('estimate')\n",
    "plt.subplot(133)\n",
    "plt.imshow(x.cpu().squeeze())\n",
    "plt.title('ground truth')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
